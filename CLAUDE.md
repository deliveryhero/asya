# CLAUDE.md

This file provides guidance to Claude Code (claude.ai/code) when working with code in this repository.

## Project Overview

Asya is an async actor-based framework for deploying AI workloads on Kubernetes. It provides a CRD-based operator pattern with automatic sidecar injection, message queue integration, and event-driven autoscaling via KEDA.

## Python Development Requirements

REQUIRED: This project uses [uv](https://github.com/astral-sh/uv) for Python package management and execution. You must have `uv` installed to work on this project.

**Installation**:
```bash
# macOS/Linux
curl -LsSf https://astral.sh/uv/install.sh | sh
```

All Python commands in this project are run via `uv` to ensure consistent dependency management and isolated environments.

## Using the Makefile

**IMPORTANT**: Always prefer using Makefile targets over direct commands. The root `Makefile` provides standardized commands for common tasks.

**Available targets** (run `make help` to see all):
- `make build` - Build all components
- `make test-all` - Run all tests (unit + integration)
- `make test-unit` - Run all unit tests (Go + Python)
- `make test-unit-sidecar` - Run sidecar unit tests only
- `make test-unit-gateway` - Run gateway unit tests only
- `make test-unit-runtime` - Run runtime unit tests only
- `make test-integration` - Run all integration tests
- `make test-integration-sidecar` - Run sidecar integration tests (with RabbitMQ)
- `make test-integration-gateway` - Run gateway integration tests (with RabbitMQ)
- `make clean-integration` - Remove docker containers from integration tests
- `make lint` - Run all linters via pre-commit (with auto-fix)
- `make clean` - Clean build artifacts
- `make build-images` - Build all Docker images
- `make load-minikube` - Load built images into Minikube
- `make load-minikube-build` - Build and load images into Minikube
- `make deploy-minikube` - Deploy full stack to Minikube
- `make port-forward-grafana` - Port-forward Grafana to localhost:3000

**Adding new commands**: If you find yourself repeating a command that's not in the Makefile, add it as a new target instead of running it manually multiple times. This ensures consistency and makes the workflow easier for everyone.

## Repository Structure

```
asya/
├── src/                     # Framework components (Go/Python)
│   ├── asya-gateway/        # MCP gateway
│   ├── asya-sidecar/        # Actor sidecar
│   ├── asya-runtime/        # Actor runtime base (Python)
│   ├── asya-actors/         # Common actor implementations
│   │   ├── happy-end/       # Terminal actor for handling successful jobs
│   │   └── error-end/       # Terminal actor for handling failed jobs
│   └── asya-otel-sidecar/   # OpenTelemetry sidecar
├── operator/                # Kubernetes operator source
│   └── config/crd/          # AsyncActor CRD (generated by Kubebuilder)
├── deploy/                  # Framework deployment
│   └── helm-charts/
│       ├── asya-operator/   # Operator Helm chart
│       └── asya-gateway/    # Gateway Helm chart
├── examples/                # Examples and reference deployments
│   ├── asyas/               # AsyncActor CRD examples
│   ├── deployment-minimal/  # Minimal framework deployment
│   └── deployment-minikube/ # Full stack for local Minikube testing
└── scripts/                 # Build and deployment scripts
    ├── build-images.sh      # Build all Docker images
    ├── load-images-minikube.sh  # Load images into Minikube
    ├── port-forward-grafana.sh  # Port-forward Grafana
    └── test-integration.sh  # Integration tests
```

## Architecture

The system is composed of four main Python/Go services located in `src/`:

### 1. asya-gateway
**Location**: `src/asya-gateway/`
**Language**: Go 1.23
**Status**: Complete implementation

MCP (Model Context Protocol) gateway implementing JSON-RPC 2.0 over HTTP. Responsibilities:
- Exposes MCP tools via JSON-RPC 2.0 endpoint (configurable via YAML)
- Creates jobs with K8s-style status tracking (Pending/Running/Succeeded/Failed/Unknown)
- Sends messages to actor queues (RabbitMQ) with routing information
- Provides REST API for job status (`GET /jobs/{id}`)
- Streams real-time job progress via Server-Sent Events (`GET /jobs/{id}/stream`)
- Accepts final status reports from terminal actors (`POST /jobs/{id}/final`)

**Configurable Tools**:
Tools are now defined in YAML files instead of hardcoded. See `src/asya-gateway/config/README.md` for details.

```yaml
# Example: config/routes.yaml
tools:
  - name: my_tool
    description: Process data
    parameters:
      input: {type: string, required: true}
      count: {type: number, default: 5}
    route: [parser, processor, finalizer]
    progress: true
    timeout: 300
```

Deploy with config:
```bash
export ASYA_CONFIG_PATH=/etc/asya/routes.yaml
./bin/gateway
```

**Key Components**:
- `internal/config/`: YAML config loading and validation
- `internal/mcp/registry.go`: Dynamic tool registration from config
- `internal/mcp/server.go`: MCP server (supports both config and hardcoded tools)
- `internal/mcp/handlers.go`: HTTP endpoints for job management and terminal actor reporting
- `internal/jobs/`: Job state management (in-memory or PostgreSQL)
- `internal/queue/`: RabbitMQ integration

**Note**: The gateway no longer consumes terminal queues directly. Deploy standalone terminal actors (happy-end, error-end) to handle final job status and report to gateway via `POST /jobs/{id}/final`.

### 2. asya-sidecar (Go Implementation)
**Location**: `src/asya-sidecar/`
**Language**: Go 1.23
**Status**: Complete implementation

Go-based sidecar implementing the Asya Actor protocol with pluggable transport layer.

**Key Components**:
- `pkg/messages/message.go`: Message and Route structures
- `internal/config/config.go`: Environment-based configuration
- `internal/transport/`: Pluggable transport interface
  - `transport.go`: Transport interface definition
  - `rabbitmq.go`: RabbitMQ implementation
- `internal/runtime/client.go`: Unix socket communication with actor runtime
- `internal/router/router.go`: Message routing logic
- `cmd/sidecar/main.go`: Application entry point

**Message Flow**:
1. Receives message from RabbitMQ queue
2. Parses route and payload: `{"route": {"steps": ["step1", "step2"], "current": 0}, "payload": <bytes>}`
3. Sends payload to actor runtime via Unix socket
4. Receives response(s) from runtime:
   - Single response: Route to next step
   - Multiple responses (fan-out): Route each to next step
   - Empty response: Send to happy-end queue
   - Error/timeout: Send to error-end queue
5. Increments route.current and sends to next destination

**Building and Running**:
```bash
# Build using Makefile (recommended)
make build

# Or build manually
cd src/asya-sidecar && go build -o bin/sidecar ./cmd/sidecar

# Run the sidecar
export ASYA_RABBITMQ_URL=amqp://guest:guest@localhost:5672/
export ASYA_QUEUE_NAME=my-queue
cd src/asya-sidecar && ./bin/sidecar
```

### 3. asya-runtime
**Location**: `src/asya-runtime/`
**Language**: Python 3.13+

A lightweight Unix socket server (`asya_runtime.py`) that receives payloads from the sidecar, calls user-defined Python functions, and returns responses. Designed to be injected into AI model containers via ConfigMap.

**Environment Variables**:
- `ASYA_HANDLER`: Full function path (required, e.g., `"my_app.handler.predict"`)
- `ASYA_SOCKET_PATH`: Unix socket path (default: `/tmp/sockets/app.sock`)
- `ASYA_SOCKET_CHMOD`: Socket permissions in octal (default: `"0o660"`, empty = skip chmod)
- `ASYA_INCLUDE_METADATA`: Include route/metadata in msg dict (default: `false`)
- `ASYA_ENABLE_OOM_DETECTION`: Enable OOM error detection (default: `true`)
- `ASYA_CUDA_CLEANUP_ON_OOM`: Clear CUDA cache on GPU OOM (default: `true`)

**Function Contract**:
Your function must accept a `msg` dict and return a dict:
```python
def your_function(msg: dict) -> dict:
    payload = msg["payload"]  # Always a dict
    # Process payload...
    return {"result": result}  # Single value or list for fan-out
```

**Socket Protocol** (length-prefix framing):
- Format: `[4 bytes: length (big-endian uint32)][N bytes: JSON payload]`
- Max message size: 4GB (uint32 max)
- Success response:
  ```json
  {
    "status": "ok",
    "result": <single dict or array of dicts>
  }
  ```
- Error response:
  ```json
  {
    "status": "error",
    "error": "error_code",
    "message": "description",
    "type": "ExceptionType",
    "severity": "recoverable|fatal",
    "retry_after": 30
  }
  ```

**Error Codes**:
- `oom_error`: RAM OOM (recoverable, triggers GC, retry after 30s)
- `cuda_oom_error`: CUDA GPU OOM (recoverable, clears cache, retry after 60s)
- `processing_error`: Exception in user function (fatal)
- `invalid_json`: JSON/UTF-8 parsing error (fatal)
- `connection_error`: Connection handling error (fatal)

**Key Features**:
- No dependencies (stdlib only)
- Automatic OOM detection and recovery (RAM + CUDA)
- Security: Input validation against path traversal and injection
- Functional design with closures (no global state)

### 4. asya-otel-sidecar
**Location**: `src/asya-otel-sidecar/`
**Language**: Python 3.13+
**Status**: Placeholder implementation

OpenTelemetry sidecar for centralized monitoring (Prometheus, Jaeger, etc.).

**Planned metrics**:
- Standard: message received/sent, processing time, idle time, error rates
- Custom (AI): time_to_first_token, token_generation_speed, prompt_tokens_count, total_tokens_count

### 5. asya-actors (Common Actors)
**Location**: `src/asya-actors/`
**Language**: Python 3.13+
**Status**: Production-ready terminal actors

Common actor implementations that can be deployed alongside your custom actors.

#### happy-end Actor
**Location**: `src/asya-actors/happy-end/`

Terminal actor for handling successfully completed jobs:
- Persists results to MinIO/S3 with structured keys: `{prefix}{date}/{hour}/{last_step}/{job_id}.json`
- Reports final status to gateway via `POST /jobs/{id}/final` (optional)
- Works with both MinIO (OpenStack) and AWS S3

**Environment Variables**:
- `ASYA_GATEWAY_URL`: Gateway HTTP endpoint (optional)
- `ASYA_S3_BUCKET`: S3/MinIO bucket (optional)
- `ASYA_S3_ENDPOINT`: MinIO endpoint (e.g., http://minio:9000, omit for AWS S3)
- `ASYA_S3_ACCESS_KEY`, `ASYA_S3_SECRET_KEY`: Credentials (optional, defaults to minioadmin)
- `ASYA_S3_BASE_PREFIX`: Key prefix (default: asya-results/)

#### error-end Actor
**Location**: `src/asya-actors/error-end/`

Terminal actor for handling failed jobs with retry logic:
- Exponential backoff retry: `delay = ASYA_ERROR_RETRY_DELAY_BASE * (2 ** retry_count)`
- Fatal error detection (no retry for processing_error, invalid_json, validation_error)
- Persists error details to MinIO/S3 for debugging
- Reports final failure to gateway via `POST /jobs/{id}/final` (optional)
- Dead letter queue handling after max retries

**Environment Variables**:
- `ASYA_GATEWAY_URL`: Gateway HTTP endpoint (optional)
- `ASYA_ERROR_MAX_RETRIES`: Maximum retry attempts (default: 3)
- `ASYA_ERROR_RETRY_DELAY_BASE`: Base delay for exponential backoff in seconds (default: 5)
- `ASYA_DLQ_NAME`: Dead letter queue name (default: dead-letter-queue)
- `ASYA_S3_BUCKET`, `ASYA_S3_ENDPOINT`, `ASYA_S3_ACCESS_KEY`, `ASYA_S3_SECRET_KEY`: Same as happy-end
- `ASYA_S3_BASE_PREFIX`: Key prefix (default: asya-errors/)

**Architecture Note**: Terminal actors are the only way to handle final job status. The gateway no longer includes built-in terminal queue consumers.

## Development Workflow

### Building

**Using Makefile (recommended)**:
```bash
# Build all components
make build

# Clean build artifacts
make clean
```

**Building Docker images**:
```bash
# Using Makefile (recommended)
make build-images                  # Build all framework images
make load-minikube                 # Load images into Minikube
make load-minikube-build          # Build and load into Minikube

# Or use scripts directly (with custom options)
./scripts/build-images.sh --tag v1.0.0    # Build with specific tag
./scripts/load-images-minikube.sh --build # Build and load
```

### Testing

**Using Makefile (recommended)**:
```bash
# Run unit tests
make test-unit

# Run integration tests (requires Docker compose)
make test-integration
```

**Integration Tests**:
The integration test suite (`make test-integration`) spins up a complete environment with:
- RabbitMQ for message queuing
- Actor runtime (Python) with a test handler
- Actor sidecar (Go) for message routing
- Automated test that publishes a message and verifies end-to-end processing

The test validates the complete message flow:
1. Message published to test-actor-queue
2. Sidecar consumes and forwards to runtime via Unix socket
3. Runtime processes with test_handler.process
4. Response routed to happy-end queue
5. Test verifies processed message in queue

**Automated deployment tests**:
```bash
# Complete test suite
cd examples && ./run-all-tests.sh

# Test Minikube deployment
cd examples/deployment-minikube && ./scripts/deploy.sh && ./scripts/test-e2e.sh

# Test all example actors
cd examples && ./test-actors.sh
```

**Manual testing** (only when necessary):
```bash
# Go components
cd src/asya-sidecar && go test ./...

# Python components (requires uv)
cd src/asya-runtime && uv run pytest
```

### Linting and Formatting

**Using Makefile (recommended)**:
```bash
# Run all linters
make lint

# Auto-fix formatting issues
make format

# Install pre-commit hooks
make install-hooks
```

### Accessing Services

**Port-forwarding** (for deployed services):
```bash
# Using Makefile (recommended)
make port-forward-grafana           # Grafana at http://localhost:3000

# Or use kubectl directly for other services
kubectl port-forward -n asya svc/rabbitmq 15672:15672        # RabbitMQ Management
kubectl port-forward -n asya svc/asya-gateway 8080:8080      # Asya Gateway (MCP)
```

## Message Schema

Messages flowing through the system:
```json
{
  "route": {
    "route": ["step1", "step2", "step3"],
    "current": 0
  },
  "payload": <arbitrary JSON or bytes>
}
```

- `route.route`: List of queue names representing the processing pipeline
- `route.current`: Index of current step (incremented by sidecar after processing)
- `payload`: Arbitrary data passed to runtime for processing

## Terminal Queues

- `happy-end`: Successful completion or empty runtime response
- `error-end`: Errors, timeouts, or parsing failures

## Adding a New Transport

To add support for a new queue system:

1. Implement the `Transport` interface in `internal/transport/`:
   ```go
   type Transport interface {
       Receive(ctx context.Context, queueName string) (QueueMessage, error)
       Send(ctx context.Context, queueName string, body []byte) error
       Ack(ctx context.Context, msg QueueMessage) error
       Nack(ctx context.Context, msg QueueMessage) error
       Close() error
   }
   ```

2. Add configuration in `internal/config/config.go`

3. Update `cmd/sidecar/main.go` to instantiate your transport

## Kubernetes Operator

**Location**: `operator/`
**Language**: Go (Kubebuilder-based)

The operator watches AsyncActor CRDs and:
- Injects sidecar containers for queue consumption
- Creates Deployments or StatefulSets based on workload type
- Configures KEDA ScaledObjects for autoscaling
- Sets up RBAC, ServiceAccounts, and Secrets
- Manages the full lifecycle of actor deployments

**Key Files**:
- `api/v1alpha1/asya_types.go`: AsyncActor CRD API definition
- `internal/controller/asya_controller.go`: Reconciliation logic
- `internal/controller/keda.go`: KEDA integration
- `config/crd/`: Generated CRD manifests (source of truth)

## Deployment Structure

### Framework Deployment (`deploy/`)

The framework deployment includes:

1. **CRDs** (`operator/config/crd/`): AsyncActor CRD generated by Kubebuilder from Go API types
2. **Operator Chart** (`deploy/helm-charts/asya-operator/`): Deploys only the operator pod
3. **Gateway Chart** (`deploy/helm-charts/asya-gateway/`): Optional MCP gateway deployment

**Quick Start - Automated (Recommended)**:
```bash
cd tests/e2e
./scripts/deploy.sh      # Full stack deployment for Kind (~5-10 minutes)
./scripts/test-e2e.sh    # Verify deployment
```

**Manual Installation**:
```bash
# 1. Install CRDs from operator source
kubectl apply -f operator/config/crd/

# 2. Install operator via Helm chart
helm install asya-operator deploy/helm-charts/asya-operator -n asya-system

# 3. (Optional) Install gateway
helm install asya-gateway deploy/helm-charts/asya-gateway -n asya
```

**Important**: The operator chart deploys only the operator pod (single Deployment). It does NOT deploy:
- CRDs (install separately as shown above)
- Actors (create AsyncActor resources after operator is running)
- KEDA (install separately if using autoscaling)

The CRD is maintained in the operator directory as the source of truth. Run `make manifests` in `operator/` to regenerate after API changes.

### Examples (`examples/`)

Reference implementations and templates:

1. **Actor Examples** (`asyas/`):
   - Various AsyncActor CRD examples (simple, StatefulSet, multi-container, etc.)
   - Copy and modify for your use case

2. **E2E Tests** (`tests/e2e/`):
   - Complete test environment for local Kubernetes testing with Kind
   - Includes RabbitMQ, PostgreSQL, Prometheus, Grafana, KEDA
   - Automated deployment and E2E testing scripts
   - Optimized for Kind local development and testing
   - Gateway exposed on http://localhost:8080
   - Grafana exposed on http://localhost:3000

**E2E Testing**:
```bash
# Deploy Kind cluster and run E2E tests
cd tests/e2e
./scripts/deploy.sh      # Deploy complete stack
./scripts/test-e2e.sh    # Run E2E tests against Kind deployment
./scripts/cleanup.sh     # Delete cluster
```

E2E tests are located in `tests/e2e/` and validate:
- MCP tool calls and job status API
- Progress tracking via SSE streaming
- Multi-step pipeline routing
- Error handling and retries

## Project Status

Framework components are feature-complete:
- **asya-sidecar**: Production-ready with RabbitMQ support
- **asya-gateway**: Complete MCP gateway implementation
- **asya-runtime**: Base library for user-defined processing logic
- **operator**: Functional CRD-based operator with KEDA integration
- **asya-otel-sidecar**: Placeholder for future monitoring integration

## Claude Code Automation

### Command Execution Policy

**IMPORTANT**: Claude Code should always prefer Makefile targets over direct commands. When working on tasks:

1. **First choice**: Use `make <target>` if available (e.g., `make test`, `make build`)
2. **Second choice**: Use scripts in `./scripts/` for deployment and infrastructure tasks
3. **Last resort**: Run direct commands only when no Makefile target or script exists

**Adding new commands**: If you find yourself needing to run the same command multiple times and it's not in the Makefile, add it as a new target to the Makefile instead of repeating the raw command.

Automation policies (allowed/denied commands) are configured in `.claude/settings.local.json`. See that file for the current configuration of what commands Claude Code can run without confirmation.

### Code Comment Guidelines

**IMPORTANT**: When making code changes, avoid adding transitional comments that only make sense in the context of the edit.

**Bad Examples** (transitional comments):
```python
connection.close()
# Message is confirmed delivered - no need to sleep
```

```python
# Increased timeout for multi-step processing
result = helper.assert_message_in_queue("happy-end", timeout=30)
```

These comments reference the previous state ("no need to sleep", "increased") which is meaningless when reading the code later without the git diff context.

**Good Examples** (explanatory comments):
```go
// Receive message from queue (blocks until message available or context cancelled)
msg, err := c.queueClient.Receive(ctx, queueName)
```

```python
poll_interval = 0.1  # 100ms polling interval
```

```python
# Verify purge completed by checking queue is empty
self._wait_for_queue_empty(queue, timeout=2)
```

These comments explain *what* the code does or *why* it does it, not how it differs from before.

**Rules**:
1. Remove transitional phrases: "no need to", "reduced from", "increased", "instead of", "don't", etc.
2. If a comment only makes sense in the context of "this replaces X", remove it entirely
3. If explaining behavior, focus on what/why, not how it changed
4. Inline value comments (like `0.1  # 100ms`) are fine when they clarify units or meaning

### Sleep Statement Policy

Avoid using `time.Sleep` (Go) or `time.sleep` (Python) in production code. Sleep statements make code flaky, introduce unnecessary delays, and hide timing bugs.

**When sleep IS allowed** (only in tests):
1. **Polling loops**: When waiting for external state changes (queue messages, file creation, service readiness)
   - Must have a timeout and poll interval
   - Must be documented with a comment explaining what is being polled
2. **Simulating processing time**: In test handlers/mocks to simulate realistic delays
   - Must be documented with a comment explaining the simulation purpose
3. **Timeout testing**: Simulating slow/hung operations to test timeout handling
   - Must be documented with a comment explaining the test scenario

**Required documentation**:
Every `time.Sleep`/`time.sleep` must have an inline comment explaining its purpose.

**Examples**:

Good (polling with clear purpose):
```go
time.Sleep(100 * time.Millisecond) // Poll interval: check socket existence every 100ms
```

```python
time.sleep(poll_interval)  # Poll RabbitMQ API for new messages
```

Good (test simulation):
```python
time.sleep(0.5)  # Simulate processing time for SSE heartbeat testing
```

Bad (no comment):
```go
time.Sleep(100 * time.Millisecond)
```

Bad (production code):
```go
// Production code should NEVER use sleep for synchronization
time.Sleep(1 * time.Second)  // Wait for service to start
```

**Alternatives to sleep**:
- Use channels, wait groups, or condition variables for synchronization (Go)
- Use event-driven patterns with callbacks or async/await (Python)
- Use blocking operations with timeouts (socket.accept, queue.get, etc.)
- Use health check endpoints with retry logic for service readiness

### Creating Pull Requests

When asked to create a PR, follow these steps:

1. **Ensure all checks pass**:
   ```bash
   make lint    # All linters must pass
   make test    # All tests must pass
   ```

2. **Commit changes** with descriptive message:
   ```bash
   git add <files>
   git commit -m "Summary of changes:
   - Detailed change 1
   - Detailed change 2
   - etc.
   ```

3. **Push to branch**:
   ```bash
   git push origin <branch-name>
   ```

4. **Create PR via gh CLI**:
   ```bash
   gh pr create --title "Title" --body "$(cat <<'EOF'
   ## Summary
   Brief description of changes

   ## Changes
   - Change 1
   - Change 2

   ## Testing
   - [ ] All linters passing (`make lint`)
   - [ ] All tests passing (`make test`)
   - [ ] Integration tests passing (`make test-integration`)
   EOF
   )"
   ```

### Reviewing Pull Requests

When asked to "review PR #N" or "address PR comments", follow this workflow:

1. **Read all PR comments and reviews**:
   ```bash
   # Get PR details
   gh pr view <PR_NUMBER> --json title,body,comments,reviews

   # Get inline review comments
   gh api repos/<owner>/<repo>/pulls/<PR_NUMBER>/comments
   ```

2. **Analyze each comment**:
   - Identify the issue/concern
   - Determine severity (critical, medium, low)
   - Locate affected files and line numbers
   - Understand the requested change

3. **Fix all issues**:
   - Make code changes to address each comment
   - Ensure fixes align with the feedback
   - Run linters and tests after each fix:
     ```bash
     make lint    # Must pass
     make test    # Must pass
     ```

4. **Reply to each comment** via gh CLI:
   ```bash
   # Reply to inline review comments
   gh api -X POST repos/<owner>/<repo>/pulls/<PR_NUMBER>/comments/<COMMENT_ID>/replies \
     -f body="✅ Fixed in commit <sha>. <Description of fix>"
   ```

5. **Add summary comment**:
   ```bash
   gh pr comment <PR_NUMBER> --body "## ✅ All Review Comments Resolved

   Thank you for the review! I've addressed all comments:

   ### Issues Fixed
   1. **<Issue 1>** - <Description>
   2. **<Issue 2>** - <Description>

   ### Verification
   - ✅ All linters passing (\`make lint\`)
   - ✅ All tests passing (\`make test\`)

   Ready for re-review!"
   ```

6. **Commit and push fixes**:
   ```bash
   git add <files>
   git commit -m "Fix PR review comments
   - Fix 1
   - Fix 2
   Addresses comments from PR #<number>"

   git push origin <branch>
   ```
